{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Logistic Regression - Cumulative Lab\n", "\n", "## Introduction\n", "\n", "In this cumulative lab, you will walk through a complete machine learning workflow with logistic regression, including data preparation, modeling (including hyperparameter tuning), and final model evaluation.\n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "* Practice identifying and applying appropriate preprocessing steps\n", "* Perform an iterative modeling process, starting from a baseline model\n", "* Practice model validation\n", "* Practice choosing a final logistic regression model and evaluating its performance"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Your Task: Complete an End-to-End ML Process with Logistic Regression on the Forest Cover Dataset\n", "\n", "![forest road](images/forest_road.jpg)\n", "\n", "<span>Photo by <a href=\"https://unsplash.com/@von_co?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Ivana Cajina</a> on <a href=\"https://unsplash.com/s/photos/forest-satellite?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Business and Data Understanding\n", "\n", "Here we will be using an adapted version of the forest cover dataset from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/covertype). Each record represents a 30 x 30 meter cell of land within Roosevelt National Forest in northern Colorado, which has been labeled as `Cover_Type` 1 for \"Cottonwood/Willow\" and `Cover_Type` 0 for \"Ponderosa Pine\". (The original dataset contained 7 cover types but we have simplified it.)\n", "\n", "The task is to predict the `Cover_Type` based on the available cartographic variables:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "import pandas as pd\n", "\n", "df = pd.read_csv('data/forest_cover.csv')  \n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As you can see, we have over 38,000 rows, each with 54 feature columns and 1 target column:\n", "\n", "* `Elevation`: Elevation in meters\n", "* `Aspect`: Aspect in degrees azimuth\n", "* `Slope`: Slope in degrees\n", "* `Horizontal_Distance_To_Hydrology`: Horizontal dist to nearest surface water features in meters\n", "* `Vertical_Distance_To_Hydrology`: Vertical dist to nearest surface water features in meters\n", "* `Horizontal_Distance_To_Roadways`: Horizontal dist to nearest roadway in meters\n", "* `Hillshade_9am`: Hillshade index at 9am, summer solstice\n", "* `Hillshade_Noon`: Hillshade index at noon, summer solstice\n", "* `Hillshade_3pm`: Hillshade index at 3pm, summer solstice\n", "* `Horizontal_Distance_To_Fire_Points`: Horizontal dist to nearest wildfire ignition points, meters\n", "* `Wilderness_Area_x`: Wilderness area designation (4 columns)\n", "* `Soil_Type_x`: Soil Type designation (40 columns)\n", "* `Cover_Type`: 1 for cottonwood/willow, 0 for ponderosa pine"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is also an imbalanced dataset, since cottonwood/willow trees are relatively rare in this forest:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "print(\"Raw Counts\")\n", "print(df[\"Cover_Type\"].value_counts())\n", "print()\n", "print(\"Percentages\")\n", "print(df[\"Cover_Type\"].value_counts(normalize=True))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If we had a model that *always* said that the cover type was ponderosa pine (class 0), what accuracy score would we get?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate text\n", "\"\"\"\n", "None\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["You will need to take this into account when working through this problem."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Requirements\n", "\n", "#### 1. Perform a Train-Test Split\n", "\n", "For a complete end-to-end ML process, we need to create a holdout set that we will use at the very end to evaluate our final model's performance.\n", "\n", "#### 2. Build and Evaluate a Baseline Model\n", "\n", "Without performing any preprocessing or hyperparameter tuning, build and evaluate a vanilla logistic regression model using log loss and `cross_val_score`.\n", "\n", "#### 3. Write a Custom Cross Validation Function\n", "\n", "Because we are using preprocessing techniques that differ for train and validation data, we will need a custom function rather than simply preprocessing the entire `X_train` and using `cross_val_score` from scikit-learn.\n", "\n", "#### 4. Build and Evaluate Additional Logistic Regression Models\n", "\n", "Using the function created in the previous step, build multiple logistic regression models with different hyperparameters in order to minimize log loss.\n", "\n", "#### 5. Choose and Evaluate a Final Model\n", "\n", "Preprocess the full training set and test set appropriately, then evaluate the final model with various classification metrics in addition to log loss."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Perform a Train-Test Split\n", "\n", "This process should be fairly familiar by now. In the cell below, use the variable `df` (that has already been created) in order to create `X` and `y`, then training and test sets using `train_test_split` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)).\n", "\n", "We'll use a random state of 42 and `stratify=y` (to ensure an even balance of fraud/not fraud rows) in the train-test split. Recall that the target is `Cover_Type`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "# Import the relevant function\n", "None\n", "\n", "# Split df into X and y\n", "X = None\n", "y = None\n", "\n", "# Perform train-test split with random_state=42 and stratify=y\n", "X_train, X_test, y_train, y_test = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check that you have the correct data shape before proceeding:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "# X and y training data should have the same number of rows\n", "assert X_train.shape[0] == y_train.shape[0] and X_train.shape[0] == 28875\n", "\n", "# X and y testing data should have the same number of rows\n", "assert X_test.shape[0] == y_test.shape[0] and X_test.shape[0] == 9626\n", "\n", "# Both X should have 33 columns\n", "assert X_train.shape[1] == X_test.shape[1] and X_train.shape[1] == 54\n", "\n", "# Both y should have 1 column\n", "assert len(y_train.shape) == len(y_test.shape) and len(y_train.shape) == 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Also, we should have roughly equal percentages of cottonwood/willow trees for train vs. test targets:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "print(\"Train percent cottonwood/willow:\", y_train.value_counts(normalize=True)[1])\n", "print(\"Test percent cottonwood/willow: \", y_test.value_counts(normalize=True)[1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Build and Evaluate a Baseline Model\n", "\n", "Using scikit-learn's `LogisticRegression` model, instantiate a classifier with `random_state=42`. Then use `cross_val_score` with `scoring=\"neg_log_loss\"` to find the average cross-validated log loss for this model on `X_train` and `y_train`.\n", "\n", "* [`LogisticRegression` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n", "* [`cross_val_score` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n", "\n", "(Similar to RMSE, the internal implementation of `cross_val_score` requires that we use \"negative log loss\" instead of just log loss. The code provided negates the result for you.)\n", "\n", "**The code below should produce a warning** but not an error. Because we have not scaled the data, we expect to get a `ConvergenceWarning` five times (once for each fold of cross validation)."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "# Import relevant class and function\n", "None\n", "None\n", "\n", "# Instantiate a LogisticRegression with random_state=42\n", "baseline_model = None\n", "\n", "# Use cross_val_score with scoring=\"neg_log_loss\" to evaluate the model\n", "# on X_train and y_train\n", "baseline_neg_log_loss_cv = None\n", "\n", "baseline_log_loss = -(baseline_neg_log_loss_cv.mean())\n", "baseline_log_loss"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ok, so we are getting the `ConvergenceWarning`s we expected, and log loss of around 0.171 with our baseline model.\n", "\n", "Is that a \"good\" log loss? That's hard to say \u2014 log loss is not particularly interpretable. \n", "\n", "If we had a model that just chose 0 (the majority class) every time, this is the log loss we would get:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "from sklearn.metrics import log_loss\n", "import numpy as np\n", "\n", "log_loss(y_train, np.zeros(len(y_train)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Loss is a metric where lower is better, so our baseline model is clearly an improvement over just guessing the majority class every time.\n", "\n", "Even though it is difficult to interpret, the 0.171 value will be a useful baseline as we continue modeling, to see if we are actually making improvements or just getting slightly better performance by chance.\n", "\n", "We will also use other metrics at the last step in order to describe the final model's performance in a more user-friendly way."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Write a Custom Cross Validation Function\n", "\n", "### Conceptual Considerations\n", "\n", "First, consider: which preprocessing steps should be taken with this dataset? Recall that our data is imbalanced, and that it caused a `ConvergenceWarning` for our baseline model."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate text\n", "\"\"\"\n", "None\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["As you likely noted above, we should use some kind of resampling technique to address the large class imbalance. Let's use `SMOTE` (synthetic minority oversampling, [documentation here](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html)), which creates synthetic examples of the minority class to help train the model.\n", "\n", "Does SMOTE work just like a typical scikit-learn transformer, where you fit the transformer on the training data then transform both the training and the test data?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate text\n", "\"\"\"\n", "None\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# __SOLUTION\n", "\"\"\"\n", "No, SMOTE does not work like that. We never want to oversample the\n", "minority class in the test data, because then we are generating\n", "metrics based on synthetic data and not actual data.\n", "\n", "Instead, we only want to fit and transform the training data, and\n", "leave the testing data alone.\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["As you also likely noted above, we should use some transformer to normalize the data. Let's use a `StandardScaler` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)).\n", "\n", "Does `StandardScaler` work just like a typical scikit-learn transformer, where you fit the transformer on the training data then transform both the training and the test data?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate text\n", "\"\"\"\n", "None\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["(At this point it's a good idea to double-check your answers against the `solution` branch to make sure you understand the setup.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Using `StratifiedKFold`\n", "\n", "As you can see from the `cross_val_score` documentation linked above, \"under the hood\" it is using `StratifiedKFold` for classification tasks.\n", "\n", "Essentially `StratifiedKFold` is just providing the information you need to make 5 separate train-test splits inside of `X_train`. Then there is other logic within `cross_val_score` to fit and evaluate the provided model.\n", "\n", "So, if our original code looked like this:\n", "\n", "```python\n", "baseline_model = LogisticRegression(random_state=42)\n", "baseline_neg_log_loss_cv = cross_val_score(baseline_model, X_train, y_train, scoring=\"neg_log_loss\")\n", "baseline_log_loss = -(baseline_neg_log_loss_cv.mean())\n", "baseline_log_loss\n", "```\n", "\n", "The equivalent of the above code using `StratifiedKFold` would look something like this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "from sklearn.metrics import make_scorer\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.base import clone\n", "\n", "# Negative log loss doesn't exist as something we can import,\n", "# but we can create it\n", "neg_log_loss = make_scorer(log_loss, greater_is_better=False, needs_proba=True)\n", "\n", "# Instantiate the model (same as previous example)\n", "baseline_model = LogisticRegression(random_state=42)\n", "\n", "# Create a list to hold the score from each fold\n", "kfold_scores = np.ndarray(5)\n", "\n", "# Instantiate a splitter object and loop over its result\n", "kfold = StratifiedKFold()\n", "for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n", "    # Extract train and validation subsets using the provided indices\n", "    X_t, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n", "    y_t, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n", "    \n", "    # Clone the provided model and fit it on the train subset\n", "    temp_model = clone(baseline_model)\n", "    temp_model.fit(X_t, y_t)\n", "    \n", "    # Evaluate the provided model on the validation subset\n", "    neg_log_loss_score = neg_log_loss(temp_model, X_val, y_val)\n", "    kfold_scores[fold] = neg_log_loss_score\n", "    \n", "-(kfold_scores.mean())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As you can see, this produced the same result as our original cross validation (including the `ConvergenceWarning`s):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "print(baseline_neg_log_loss_cv)\n", "print(kfold_scores)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So, what is the point of doing it this way, instead of the much-shorter `cross_val_score` approach?\n", "\n", "**Using `StratifiedKFold` \"by hand\" allows us to customize what happens inside of that loop.**\n", "\n", "Therefore we can apply these preprocessing techniques appropriately:\n", "\n", "1. Fit a `SMOTE` object and transform only the training subset\n", "2. Fit a `StandardScaler` object on the training subset (not the full training data) and transform both the train and test subsets"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Writing a Custom Cross Validation Function with `StratifiedKFold`\n", "\n", "In the cell below, we have set up a function `custom_cross_val_score` that has an interface that resembles the `cross_val_score` function from scikit-learn.\n", "\n", "Most of it is set up for you already, all you need to do is add the `SMOTE` and `StandardScaler` steps described above."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Replace None with appropriate code\n", "\n", "# Import relevant sklearn and imblearn classes\n", "None\n", "None\n", "\n", "def custom_cross_val_score(estimator, X, y):\n", "    # Create a list to hold the score from each fold\n", "    kfold_scores = np.ndarray(5)\n", "\n", "    # Instantiate a splitter object and loop over its result\n", "    kfold = StratifiedKFold(n_splits=5)\n", "    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n", "        # Extract train and validation subsets using the provided indices\n", "        X_t, X_val = X.iloc[train_index], X.iloc[val_index]\n", "        y_t, y_val = y.iloc[train_index], y.iloc[val_index]\n", "        \n", "        # Instantiate StandardScaler\n", "        scaler = None\n", "        # Fit and transform X_t\n", "        X_t_scaled = None\n", "        # Transform X_val\n", "        X_val_scaled = None\n", "        \n", "        # Instantiate SMOTE with random_state=42 and sampling_strategy=0.28\n", "        sm = None\n", "        # Fit and transform X_t_scaled and y_t using sm\n", "        X_t_oversampled, y_t_oversampled = None\n", "        \n", "        # Clone the provided model and fit it on the train subset\n", "        temp_model = clone(estimator)\n", "        temp_model.fit(X_t_oversampled, y_t_oversampled)\n", "        \n", "        # Evaluate the provided model on the validation subset\n", "        neg_log_loss_score = neg_log_loss(temp_model, X_val_scaled, y_val)\n", "        kfold_scores[fold] = neg_log_loss_score\n", "        \n", "    return kfold_scores\n", "        \n", "model_with_preprocessing = LogisticRegression(random_state=42, class_weight={1: 0.28})\n", "preprocessed_neg_log_loss_cv = custom_cross_val_score(model_with_preprocessing, X_train, y_train)\n", "- (preprocessed_neg_log_loss_cv.mean())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The output you get should be about 0.132, and there should no longer be a `ConvergenceWarning`.\n", "\n", "If you're not getting the right output, double check that you are applying the correct transformations to the correct variables:\n", "\n", "1. `X_t` should be scaled to create `X_t_scaled`, then `X_t_scaled` should be resampled to create `X_t_oversampled`, then `X_t_oversampled` should be used to fit the model\n", "2. `X_val` should be scaled to create `X_val_scaled`, then `X_val_scaled` should be used to evaluate `neg_log_loss`\n", "3. `y_t` should be resampled to create `y_t_oversampled`, then `y_t_oversampled` should be used to fit the model\n", "4. `y_val` should not be transformed in any way. It should just be used to evaluate `neg_log_loss`\n", "\n", "Another thing to check is that you used `sampling_strategy=0.28` when you instantiated the `SMOTE` object."]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you are getting the right output, great!  Let's compare that to our baseline log loss:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "print(-baseline_neg_log_loss_cv.mean())\n", "print(-preprocessed_neg_log_loss_cv.mean())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Looks like our preprocessing with `StandardScaler` and `SMOTE` has provided some improvement over the baseline! Let's move on to Step 4."]}], "metadata": {"kernelspec": {"display_name": "Python (learn-env)", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}